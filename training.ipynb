{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import mkl\n",
    "mkl.get_max_threads()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage.measurements import label\n",
    "from skimage.feature import hog\n",
    "import cv2\n",
    "from glob import glob\n",
    "import time\n",
    "import os\n",
    "import pipeline as pl\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import Input, Dense, Activation, Dropout, Flatten\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Input, Concatenate, Add, Cropping2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Reload custum module everytime\n",
    "%load_ext autoreload\n",
    "%aimport pipeline\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mldata_path = '/home/timo/Documents/mldata/project_5/'    \n",
    "dataset = pl.get_image_files(mldata_path)\n",
    "print(len(dataset['files']))\n",
    "print(len(dataset['labels']))\n",
    "dataset['images'] = []\n",
    "for idx in range(0, len(dataset['files'])):\n",
    "    dataset['images'].append(mpimg.imread(dataset['files'][idx]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Image Value: \", dataset['images'][0][0,0,0])\n",
    "print(type(dataset['images'][0][0,0,0]))\n",
    "print(type(dataset['images'][0]))\n",
    "pl.print_image_properties(dataset['images'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = pl.generate_batch_debug(1500, dataset, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "nb_epochs  = 20\n",
    "steps_per_training_epoch = 100\n",
    "steps_per_validation_epoch = np.max((1, int(0.1 * steps_per_training_epoch)) )\n",
    "init = Input(shape=(64, 64, 3))\n",
    "# Convolutional layers\n",
    "x    = Conv2D(16, (3,3), activation='relu', padding='same', strides=(2,2) )(init)\n",
    "x    = Conv2D(32, (3,3), activation='relu', padding='same', strides=(1,1) )(x)\n",
    "x    = Dropout(0.4)(x)\n",
    "x    = Conv2D(32, (3,3), activation='relu', padding='same', strides=(2,2) )(x)\n",
    "x    = Conv2D(64, (3,3), activation='relu', padding='same', strides=(2,2) )(x)\n",
    "x    = Dropout(0.6)(x)\n",
    "x    = Conv2D(1, (8,8), activation='sigmoid', padding='valid', strides=(1,1) )(x)\n",
    "out    = Flatten()(x)   \n",
    "model = Model(init, out)\n",
    "\n",
    "model.summary()\n",
    "print(\"Set up training configuration ...\")\n",
    "\n",
    "\n",
    "optimizer = Adam()\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_batch_generator = pl.generate_batch(batch_size,\n",
    "                                              dataset,\n",
    "                                              'train')\n",
    "\n",
    "validation_batch_generator = pl.generate_batch(batch_size,\n",
    "                                                dataset,\n",
    "                                                'validation')\n",
    "\n",
    "print(\"Start training the model ...\")\n",
    "with tf.device('/gpu:0'):\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    history = model.fit_generator(training_batch_generator,\n",
    "                                  steps_per_epoch=steps_per_training_epoch,\n",
    "                                  epochs=nb_epochs,\n",
    "                                  validation_data=validation_batch_generator,\n",
    "                                  validation_steps=steps_per_validation_epoch,\n",
    "                                  verbose=1)\n",
    "\n",
    "\n",
    "model.save('/home/timo/Documents/mldata/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "plt.semilogy(history.history['loss'], 'r')\n",
    "plt.semilogy(history.history['val_loss'])\n",
    "plt.grid('on')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], 'r')\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
